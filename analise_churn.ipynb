{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52a4a379",
   "metadata": {},
   "source": [
    "# Análise de Churn — Telco Customer Churn\n",
    "\n",
    "Resumo rápido\n",
    "- Objetivo: identificar clientes com maior probabilidade de churn e definir um ponto de operação (threshold) que equilibre ação e custo para campanhas de retenção.\n",
    "- Dataset: `WA_Fn-UseC_-Telco-Customer-Churn.csv` (dados de clientes de uma operadora de telecom).\n",
    "- Resultado principal: usando LogisticRegression com `class_weight='balanced'` conseguimos elevar o recall para ~80% (trade-off com precisão).\n",
    "\n",
    "Como usar este notebook\n",
    "1. Carregamento & Limpeza — carrega os dados e aplica conversões básicas.\n",
    "2. Análise Exploratória (EDA) — visualizações e estatísticas descritivas.\n",
    "3. Modelagem — baselines (LogisticRegression, RandomForest) e comparação.\n",
    "4. Tratamento de Desbalanceamento — class_weight e SMOTE testados.\n",
    "5. Análise de Trade-off e Escolha do Threshold — curva precision-recall, seleção de thresholds e exemplo com matriz de confusão.\n",
    "6. Conclusão e próximos passos.\n",
    "\n",
    "Artefatos (na pasta `output/`)\n",
    "- PR curve: `pr_curve_logreg_classweight.png`\n",
    "- Tabela de thresholds: `pr_thresholds_logreg_classweight.csv`\n",
    "- Modelos salvos: `LogisticRegression_class_weight.joblib`, `RandomForest_smote.joblib`, etc.\n",
    "- Resumos: `model_comparison_balance.csv`, `selected_thresholds_summary.csv`\n",
    "\n",
    "Nota: algumas células incluem saídas estáticas (imagens e relatórios já gerados) para visualização imediata sem necessidade de executar todo o notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2c0f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamento e limpeza inicial\n",
    "# Aqui carregamos o CSV e aplicamos conversões necessárias (TotalCharges -> num, remover customerID)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DATA_PATH = r\"c:\\Users\\Gabriel\\Downloads\\LLM\\WA_Fn-UseC_-Telco-Customer-Churn.csv\"\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print('Shape original:', df.shape)\n",
    "\n",
    "# Converter TotalCharges para numérico (algumas linhas estão vazias)\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "print('TotalCharges NaN before drop:', df['TotalCharges'].isnull().sum())\n",
    "\n",
    "# Remover linhas com TotalCharges NaN\n",
    "df = df.dropna(subset=['TotalCharges']).copy()\n",
    "\n",
    "# Ajustes de tipos e limpeza simples\n",
    "df['SeniorCitizen'] = df['SeniorCitizen'].astype('category')\n",
    "# customerID não é usado como feature\n",
    "if 'customerID' in df.columns:\n",
    "    df = df.drop(columns=['customerID'])\n",
    "\n",
    "# Normalizar valores \"No internet service\" e \"No phone service\" para variáveis booleanas\n",
    "cols_replace_no = ['OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies','MultipleLines']\n",
    "for c in cols_replace_no:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].replace({'No internet service':'No', 'No phone service':'No'})\n",
    "\n",
    "print('Shape after cleaning:', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d1e25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelagem baseline e comparação\n",
    "# Treinamos dois modelos simples: LogisticRegression e RandomForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "import joblib\n",
    "import sklearn\n",
    "\n",
    "# separar X/y\n",
    "y = df['Churn'].map({'Yes':1,'No':0})\n",
    "X = df.drop(columns=['Churn'])\n",
    "\n",
    "# colunas numéricas e categóricas\n",
    "num_cols = ['tenure','MonthlyCharges','TotalCharges']\n",
    "cat_cols = [c for c in X.columns if c not in num_cols]\n",
    "\n",
    "# compatibiliza OneHotEncoder conforme a versão do sklearn\n",
    "v = sklearn.__version__.split('.')\n",
    "major, minor = int(v[0]), int(v[1]) if len(v)>1 else 0\n",
    "if major > 1 or (major == 1 and minor >= 2):\n",
    "    from sklearn.preprocessing import OneHotEncoder as OHE\n",
    "    ohe = OHE(handle_unknown='ignore', sparse_output=False)\n",
    "else:\n",
    "    from sklearn.preprocessing import OneHotEncoder as OHE\n",
    "    ohe = OHE(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), num_cols),\n",
    "    ('cat', ohe, cat_cols)\n",
    "])\n",
    "\n",
    "# Split para treino/teste\n",
    "a = 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=a)\n",
    "\n",
    "# LogisticRegression com class_weight='balanced' (bom para recall)\n",
    "log_pipe = Pipeline([\n",
    "    ('pre', preprocessor),\n",
    "    ('clf', LogisticRegression(max_iter=1000, class_weight='balanced'))\n",
    "])\n",
    "log_pipe.fit(X_train, y_train)\n",
    "pred_log = log_pipe.predict(X_test)\n",
    "probs_log = log_pipe.predict_proba(X_test)[:,1]\n",
    "print('LogisticRegression (class_weight)')\n",
    "print(classification_report(y_test, pred_log))\n",
    "print('ROC AUC:', roc_auc_score(y_test, probs_log))\n",
    "joblib.dump(log_pipe, 'output/LogisticRegression_class_weight.joblib')\n",
    "\n",
    "# RandomForest baseline (pode ser usado com SMOTE)\n",
    "rf_pipe = Pipeline([\n",
    "    ('pre', preprocessor),\n",
    "    ('clf', RandomForestClassifier(n_estimators=200, random_state=42))\n",
    "])\n",
    "rf_pipe.fit(X_train, y_train)\n",
    "pred_rf = rf_pipe.predict(X_test)\n",
    "probs_rf = rf_pipe.predict_proba(X_test)[:,1]\n",
    "print('RandomForest')\n",
    "print(classification_report(y_test, pred_rf))\n",
    "print('ROC AUC:', roc_auc_score(y_test, probs_rf))\n",
    "joblib.dump(rf_pipe, 'output/RandomForest_baseline.joblib')\n",
    "\n",
    "print('Pipelines salvos em output/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670cbdef",
   "metadata": {},
   "source": [
    "## Análise de Trade-off e Escolha do Threshold\n",
    "\n",
    "Nesta seção vamos analisar o trade-off entre precisão e recall para o modelo LogisticRegression com `class_weight='balanced'`. Usamos a curva Precision-Recall e uma tabela de thresholds previamente gerada para escolher pontos de operação.\n",
    "\n",
    "Passos:\n",
    "- Exibir curva Precision-Recall\n",
    "- Explicar implicações de negócio do trade-off\n",
    "- Sugerir 3 thresholds operacionais: alto recall, balanceado e alta precisão\n",
    "- Para o threshold balanceado: calcular matriz de confusão e métricas finais\n",
    "\n",
    "Os artefatos utilizados (gerados anteriormente):\n",
    "- `output/pr_curve_logreg_classweight.png`\n",
    "- `output/pr_thresholds_logreg_classweight.csv`\n",
    "- `output/LogisticRegression_class_weight.joblib` (pipeline salvo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cd4e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise de trade-off: carregar artefatos gerados (PR curve e tabela de thresholds)\n",
    "import pandas as pd\n",
    "from IPython.display import Image, display\n",
    "import joblib\n",
    "\n",
    "OUT_DIR = r\"c:\\Users\\Gabriel\\Downloads\\LLM\\output\"\n",
    "\n",
    "# carregar thresholds\n",
    "th = pd.read_csv(OUT_DIR + r\"\\pr_thresholds_logreg_classweight.csv\")\n",
    "print('Thresholds (exemplo - head):')\n",
    "print(th.head())\n",
    "\n",
    "# exibir PR curve gerada\n",
    "display(Image(filename=OUT_DIR + r\"\\pr_curve_logreg_classweight.png\"))\n",
    "\n",
    "# carregar pipeline log\n",
    "pipe = joblib.load(OUT_DIR + r\"\\LogisticRegression_class_weight.joblib\")\n",
    "\n",
    "# carregar dataset limpo e probabilidades para análise (mostraremos métricas em célula posterior)\n",
    "df = pd.read_csv(r\"c:\\Users\\Gabriel\\Downloads\\LLM\\WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "df = df.dropna(subset=['TotalCharges']).copy()\n",
    "y = df['Churn'].map({'Yes':1,'No':0})\n",
    "X = df.drop(columns=['Churn','customerID'], errors='ignore')\n",
    "probs = pipe.predict_proba(X)[:,1]\n",
    "print('Probabilidades calculadas para todo o dataset (usadas para análise de thresholds)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bf60a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Escolha de 3 pontos de operação (thresholds) e exemplo prático\n",
    "\n",
    "A partir da tabela de thresholds gerada, propomos três pontos de operação:\n",
    "\n",
    "- Alto recall (prioriza encontrar a maior parte dos churners).\n",
    "- Balanceado (compromisso entre precisão e recall, otimiza F1).\n",
    "- Alta precisão (evitar falsos positivos, útil quando custo de ação é alto).\n",
    "\n",
    "Os valores calculados automaticamente foram (resumo):\n",
    "\n",
    "- Alto recall — threshold = 0.005816 — precision ≈ 0.266, recall = 1.000, F1 ≈ 0.420\n",
    "- Balanceado — threshold = 0.549243 — precision ≈ 0.538, recall ≈ 0.788, F1 ≈ 0.640\n",
    "- Alta precisão — threshold = 1.000000 — precision = 1.000, recall = 0.000\n",
    "\n",
    "Matriz de confusão para o threshold 'balanceado' (threshold = 0.549243):\n",
    "\n",
    "```\n",
    "[[3898, 1265],\n",
    " [ 396, 1473]]\n",
    "```\n",
    "\n",
    "Classification report (balanceado):\n",
    "\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0     0.9078    0.7550    0.8244      5163\n",
    "           1     0.5380    0.7881    0.6395      1869\n",
    "\n",
    "    accuracy                         0.7638      7032\n",
    "   macro avg     0.7229    0.7716    0.7319      7032\n",
    "weighted avg     0.8095    0.7638    0.7752      7032\n",
    "```\n",
    "\n",
    "Interpretação de negócio resumida:\n",
    "- O threshold balanceado captura ~79% dos churners (bom para campanhas de retenção), com precisão aceitável (~54%).\n",
    "- Se há capacidade para validar mais clientes, reduzir o threshold aumenta recall mas aumenta custo por falsos positivos.\n",
    "- Próximo passo: testar campanhas piloto com o threshold balanceado e medir taxa de conversão de ações de retenção para avaliar custo-benefício.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50420fa",
   "metadata": {},
   "source": [
    "### Escolha de 3 pontos de operação (thresholds) e exemplo prático\n",
    "\n",
    "A partir da tabela de thresholds gerada, sugerimos três pontos de operação:\n",
    "\n",
    "1. Alto recall (prioriza encontrar a maior parte dos churners)\n",
    "   - threshold = 0.005816\n",
    "   - precision ≈ 0.2658, recall = 1.0000, F1 ≈ 0.4200\n",
    "   - Observação: identifica todos os churners mas gera muitos falsos positivos.\n",
    "\n",
    "2. Balanceado (maximiza F1 aproximado)\n",
    "   - threshold = 0.549243\n",
    "   - precision ≈ 0.5380, recall ≈ 0.7881, F1 ≈ 0.6395\n",
    "\n",
    "3. Alta precisão (prioriza evitar falsos positivos)\n",
    "   - threshold = 1.000000\n",
    "   - precision = 1.0, recall = 0.0, F1 = 0.0\n",
    "   - Observação: threshold=1 significa classificar como churn apenas se P=1; prático somente como referência extrema.\n",
    "\n",
    "Abaixo está a matriz de confusão e o classification report para o threshold 'balanceado' (threshold = 0.549243):\n",
    "\n",
    "Confusion matrix (linhas=verdadeiro, colunas=predito):\n",
    "\n",
    "[[3898, 1265],\n",
    " [ 396, 1473]]\n",
    "\n",
    "Classification report (balanceado):\n",
    "\n",
    "precision recall f1-score support\n",
    "\n",
    "0 0.9078 0.7550 0.8244 5163\n",
    "1 0.5380 0.7881 0.6395 1869\n",
    "\n",
    "accuracy 0.7638 7032\n",
    "macro avg 0.7229 0.7716 0.7319 7032\n",
    "weighted avg 0.8095 0.7638 0.7752 7032\n",
    "\n",
    "A curva Precision-Recall também está incluída acima para referência visual.\n",
    "\n",
    "Interpretação de negócio rápida:\n",
    "- Se o objetivo é reduzir churn proativamente, geralmente priorizamos recall (capturar a maior parcela possível de churners). O ponto 'balanceado' oferece um bom compromisso: captura ~78.8% dos churners enquanto mantém precisão em ~53.8%.\n",
    "- O ponto 'alto recall' garante quase nenhum churn perdido, mas exigiria validar muitas ações (alto custo por falsos positivos).\n",
    "- Recomendação: começar com o threshold 'balanceado' e ajustar conforme capacidade operacional para lidar com falsos positivos; para campanhas agressivas, mover para um threshold menor (aumentando recall)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfe12ff",
   "metadata": {},
   "source": [
    "## Minhas Conclusões e Próximos Passos\n",
    "\n",
    "    > Conclusões Pessoais\n",
    "No início do projeto, o primeiro modelo que treinei apresentou uma acurácia de 80%, o que inicialmente parecia um ótimo resultado. No entanto, o que eu aprendi foi que uma única métrica, como a acurácia, pode ser enganosa, especialmente em problemas de negócio como este.\n",
    "\n",
    " A lição mais importante para mim foi quando analisei a métrica de Recall e percebi que o modelo estava falhando em identificar 43% dos clientes que realmente cancelariam. Entendi que, para a empresa, era muito mais valioso identificar corretamente um cliente em risco (alto Recall) do que apenas acertar a previsão geral. Foi nesse momento que o foco do projeto mudou de \"criar um modelo preciso\" para \"criar um modelo útil\".\n",
    "\n",
    "A decisão de aplicar a técnica de class_weight para tratar o desbalanceamento dos dados foi o ponto de virada. Ao fazer isso, consegui elevar o Recall para 80%, transformando o modelo de uma curiosidade estatística para uma ferramenta de negócio realmente útil, capaz de guiar ações proativas de retenção e potencialmente salvar uma receita significativa para a empresa.\n",
    "\n",
    "    > Próximos Passos\n",
    "Monitoramento e Operacionalização: O próximo passo natural seria implementar este modelo em um ambiente de produção. Uma sugestão seria criar um dashboard (em Power BI, por exemplo) que consumisse as previsões do modelo e mostrasse para a equipe de negócio, de forma diária ou semanal, a lista de clientes com maior risco de churn.\n",
    "\n",
    "Colaboração Interdepartamental: Com essa lista em mãos, eu recomendaria trabalhar diretamente com a equipe de Marketing para desenhar e executar campanhas de retenção direcionadas, como oferecer um desconto ou um benefício específico para os clientes identificados pelo modelo.\n",
    "\n",
    "Melhoria Contínua: Por fim, seria crucial monitorar a performance do modelo ao longo do tempo (uma prática conhecida como MLOps) para garantir que ele continue preciso à medida que novos dados chegam, e re-treiná-lo periodicamente para capturar novas tendências de comportamento dos clientes."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
